# ğŸ’¼ Salary Prediction Using Machine Learning

## ğŸ“Œ Project Overview
This project aims to predict employee salaries using various Machine Learning regression algorithms.  
The prediction is based on features such as age, education, experience, job level, and working hours.

Multiple models were trained and evaluated to identify the most suitable algorithm for salary prediction.

---

## ğŸ“Š Dataset Description
The dataset contains **5000 records** with the following features:

| Feature Name | Description |
|-------------|------------|
| Age | Age of the employee |
| Education_Years | Years of education |
| Experience_Years | Total years of work experience |
| Job_Level | Job seniority level |
| Hours_Per_Week | Average working hours per week |
| Salary | Annual salary (Target Variable) |

---

## ğŸ” Exploratory Data Analysis (EDA)
The following EDA steps were performed:

- Dataset overview and summary statistics
- Correlation analysis using heatmap
- Outlier detection using boxplots and IQR method

### Key Observations:
- Strong correlation between **Experience_Years** and **Salary**
- High multicollinearity observed between **Age** and **Experience**
- Minimal impact of outliers on overall model performance

---

## ğŸ§ª Feature Engineering
- Input features (`X`) and target variable (`y`) were separated
- Train-test split applied (80% training, 20% testing)
- Feature scaling performed using **StandardScaler**

---

## ğŸ¤– Machine Learning Models Used
The following regression models were trained and evaluated:

1. Linear Regression  
2. Ridge Regression  
3. Lasso Regression  
4. K-Nearest Neighbors (KNN)  
5. Support Vector Regression (SVR)  
6. Decision Tree Regression  
7. Random Forest Regression  
8. Gradient Boosting Regression  

---

## ğŸ“ˆ Model Performance Comparison

| Model | RÂ² Score |
|-----|---------|
| Linear Regression | **0.9163** |
| Ridge Regression | 0.9163 |
| Lasso Regression | 0.9162 |
| Gradient Boosting | 0.9129 |
| Random Forest | 0.8949 |
| KNN | 0.8945 |
| Decision Tree | 0.8288 |
| SVR | 0.0316 |

---

## âœ… Results & Insights
- Linear, Ridge, and Lasso Regression achieved the highest RÂ² scores
- Indicates a **strong linear relationship** between features and salary
- Ensemble models performed well but did not outperform linear models
- SVR showed poor performance due to lack of hyperparameter tuning and sensitivity to scaling

---

## ğŸ† Final Model Selection
**Linear Regression** was selected as the final model due to:
- Highest accuracy
- Simplicity
- Strong interpretability
- Minimal overfitting

---

## ğŸ§  Conclusion
The project demonstrates that salary prediction can be effectively achieved using linear models when the data exhibits linear patterns. Ridge and Lasso regression helped confirm that multicollinearity had minimal impact on predictive performance. Overall, Linear Regression proved to be the most efficient and reliable model for this dataset.

---

## ğŸš€ Future Improvements
- Hyperparameter tuning using GridSearchCV
- Cross-validation
- Model deployment using Streamlit or Flask
- Use of real-world salary datasets

---

## ğŸ› ï¸ Technologies Used
- Python
- Pandas, NumPy
- Matplotlib, Seaborn
- Scikit-learn
- Jupyter Notebook

---


